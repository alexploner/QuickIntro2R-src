---
title: "Introduction to R/RStudio"
author: "Alexander Ploner"
date: '2022-11-22'
output:
  tint::tintPdf:
    highlight: tango
classoption: a4paper
header-includes:
-   \usepackage{fancyhdr}
-   \pagestyle{fancy}
-   \renewcommand{\headrulewidth}{1pt}
---

```{r licence, include = FALSE}
## This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 
## International License, see http://creativecommons.org/licenses/by-nc-sa/4.0/
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, prompt = TRUE, comment = NA, collapse = TRUE)
## Note that we selectively pretend that our data/work directory is something 
## generic and reasonable sounding, but it can be something different
## 
## This needs some care when knitting things
## 
## Set your directories here: .showDir is what is displayed, .trueDir is the 
## place where we actually store the data, which is just the faux project directory
##  that comes with this .Rmd file
.showDir <- "Z:/OmicsDataAnalysis"
.trueDir <- normalizePath("./proj", winslash = "/")
## Set this for knitr
knitr::opts_knit$set(root.dir = .trueDir)
## We manage this via output hooks that 
## As seen in https://bookdown.org/yihui/rmarkdown-cookbook/output-hooks.html
local({
	substitute_dir <- function(x)
	{
		gsub(.trueDir, .showDir, x, fixed = TRUE)
	}
  hook_old <- knitr::knit_hooks$get("output")  # save the old hook
  knitr::knit_hooks$set(output = function(x, options) {
    hook_old(substitute_dir(x), options)
  })
  ## NOTE: for source, we replace the actual string .trueDir with the content of .showDir
	substitute_dir_q <- function(x)
	{
		gsub(".trueDir", paste0("\"", .showDir, "\""), x, fixed = TRUE)
	}
  hook_old <- knitr::knit_hooks$get("source")  # save the old hook
  knitr::knit_hooks$set(source = function(x, options) {
  	hook_old(substitute_dir_q(x), options)
  })
})
```

# This document

This is a short introduction to working with R/RStudio, covering the basics of working with the commandline, data types and data structures, and organising a simple analysis workflow. No previous exposure to R or RStudio is assumed. I strongly recommend that as a first-time reader, you work through the examples shown in the text at a computer. 

The latest version of this document, as well as the accompanying data files and example scripts, are available from Github.^[[github.com/alexploner/QuickIntro2R](https://github.com/alexploner/QuickIntro2R)]

This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.^[[creativecommons.org/licenses/by-nc-sa/4.0/](https://creativecommons.org/licenses/by-nc-sa/4.0/)]


# Background

R is a free software environment for statistical computing and graphics. 

\begin{marginfigure}
\centering 
\includegraphics[width=\textwidth]{figures/00_Rproject_web.png}\caption{R homepage \url{https://www.r-project.org/}}
\end{marginfigure}

Specifically, R is 

1. a program for statistical data analysis. Compared to software with similar functionality, R has a strong focus on interactive analysis (unlike the typical batch analysis in SAS) at a command prompt (unlike the graphical user interface of SPSS). 

2. a general-purpose programming language. R is an interpreted language (like Python, and unlike C or C++). Essentially, any kind of data handling or -analysis method can be implemented in R. This also means that existing methods can be combined into complex analysis workflows through R script files. 

3. the infrastructure for a large number of add-on packages that implement methods in statistics, data processing, bioinformatics, machine learning and many other disciplines.^[[cran.r-project.org/web/packages](https://cran.r-project.org/web/packages/)] ^[[www.bioconductor.org/packages](https://www.bioconductor.org/packages)] 

RStudio is an integrated development environment built on top of R. It provides a graphical user interface around the R console, including a code editor, a file browser, a help viewer, a tab for local data management and other utilities. In principle, all of this functionality is also available in R via commands and add-on packages, but the clean structure and tight integration of RStudio makes the learning process easier for many beginners. RStudio has an additional focus on data science and related software development, some aspects of which can be useful for data analysis (e.g. version control integration via git), whereas others are more developer-oriented (e.g. javascript-integration via shiny).

Both R and RStudio are open source software, and freely available online^[Installers can be run with defaults.], but where R is community-developed and non-profit^[[www.r-project.org/foundation/](https://www.r-project.org/foundation/)], RStudio is the product of a commercial entity^[[https://posit.co/about/](https://posit.co/about/)].

The RStudio program window is typically split into up to four different quadrants or _panes_. Figure 1 shows a typical configuration with three panes: 
\begin{figure*}
\centering 
\includegraphics[width=\textwidth]{figures/01_RStudio_3pane_fresh.png}\caption{RStudio running R 4.2.2}
\end{figure*}

* The large pane to the left showing the R start-up message is the **console**. This is the main window, where the user types commands, and numerical results are displayed. The RStudio console is identical in function and appearance to the console window in the underlying R software. 

* The smaller top right pane shows the **Environment** tab, which displays all currently defined objects (like data sets or analysis results) in a the current R session. Figure 1 shows RStudio at the start of a session, so no objects are defined yet, and the environment is empty.

* In the bottom right panel, we see the **Files** tab, which lists the files in the current working directory. This pane works as an internal file browser, where the user can travel through the directory hierarchy on the hard disk and inspect and manipulate files.  

Note that the two smaller panes are _tabbed_, i.e. other functionality is available in separate tabs (like _History_ on the top and _Packages_ and _Plots_ on the bottom). This will be discussed in more detail below.

\newpage

# Working interactively

## At the prompt

The basic workflow for interactive data analysis looks like this:

1. Start RStudio

2. In the console pane (at the command prompt `>`), a steady loop:`r tufte::margin_note("Note: you can browse through previous input via the arrow keys, edit and re-use it. This minimzes typing and allows for rapid incremental refinement of the analysis.")`

    * Type input (**expression**, see below), hit return
    * R evaluates input and displays result (text output, plot)
    * Based on results, provide new input (expression) 

3. Quit (and save, if necessary)

## Simple expressions

At the most basic level, R can work as a glorified calculator for numerical expressions that consist simply of numbers and basic arithmetic operations:^[Text after the prompt > is typed by you, text below, usually starting with [1], is output generated by R.]
```{r}
3
3+4*2
```
R also uses character expressions (strings), e.g. to keep track of group identifiers in data or to define labels for plotting. Character values are enclosed in single `'` or double `"` quotation marks:
```{r}
"My name is"
'Earl'
```
R also uses logical (or boolean) expressions, e.g. to select subsets of data or to test for conditions. These expressions have only two possible values, `TRUE` and `FALSE`. We can use comparison operations on numbers or characters (as well as other data types) to create logical expressions: 
```{r}
TRUE
3 < 4
"Earl" == "earl"
```

## Functions

Everything interesting in R is done via _functions_. These are pre-packaged pieces of code that can perform a specific task. Functions have names (generally), and zero, one or more _arguments_, i.e. slots for pieces of information that the function either operates upon (data), or that tell the function what to do (flags, parameters). 

In order to run (execute) a function, you type its name at the console, followed by a pair of parentheses with the arguments for what you want the function to do, separated by commas (and then hit return, of course).

`r tufte::newthought("Example: functions")`

The function `sqrt` calculates the square root. It takes one numerical argument, and returns one numerical value, which is the desired result:
```{r}
sqrt(4)
```
The function `paste` takes two or more character arguments, and returns one character result, which is just the joined arguments, separated by an empty space:
```{r}
paste("My name is", "Earl")
```
The function `log` calculates by default the natural logarithm (for base $e$). Like the square root, it takes one numerical argument, and returns the numerical result:
```{r}
log(10)
```
However, `log` has a second argument, called `base`, which you can use to specify a different base for the logarithm. So you can calculate the common logarithm (for base 10) and the binary logarithm (for base 2) like this:
```{r}
log(10, base = 10)
log(10, base = 2)
```
The function `getwd` takes no arguments, and returns a string with the current working directory, which is the path to the directory (folder) where R by default reads and writes files^[Note: R uses slashes (`/`), not backslashes (`\`), for separating file- and folder names in a path.]:
```{r, output = TRUE}
getwd()
```
Note that you still need to add an (empty) pair of parentheses to indicate that you want the function to run, even though no argument is given.

The functions in the examples so far do their job by returning a numerical or string result. This is the most common way to work with functions in R: you feed some data to a function, which returns a result, which you then can feed into another function, and so on. In some situations however, you want a function to simply _do_ something, e.g. create a plot or write data to a file^[This is generally described as the function being run for its _side effect_. This is somewhat misleading, as this is often the only thing you are interested in.] An example for this kind of function is `browseURL`, which takes a character argument with the URL we want to visit, and opens the default browser on your system pointed at that address:
```{r, eval=FALSE}
 browseURL("https://cran.r-project.org")
```

`r tufte::newthought("Finding functions")`

The functions in the examples above are all part of base R, and are immediately available at the command prompt after starting R/RStudio. Most other functions however live in specialized add-on packages, which need to be loaded before you can use their functions; see the section on R packages below for details.

Learning how to use functions, and what functions to use in order to get a task done, is the hardest part when starting with R. To help you with this, R and its add-on packages have large amounts of documentation available. In the simplest case, when you remember the name of the function, you can just type 
```{r, eval=FALSE}
?t.test
```
at the command line; this will open the corresponding documentation in a separate window. 

\begin{marginfigure}
\centering 
\includegraphics[width=\textwidth]{figures/02_RStudio_Help_ttest.png}\caption{RStudio Help tab}
\end{marginfigure}

If you only kind of remember the name of the function, e.g. something with "test", you can type `r tufte::margin_note("Note: \\texttt{apropos} is again just an R function, which takes a character expression with the string of interest as argument, and returns a series of character expressions, which are the names of the functions that match the string.")`
```{r, eval=FALSE}
apropos("test")
```
to list all currently available functions with "test" in their name. 

A very useful feature is also _tab-expansion_: when typing the function name in RStudio, hitting the tabulator-key will open a context menu at the cursor that lists all available function names that complete the already typed text; this list is scrollable, reactive (i.e. more typing narrows the list), and displays the help text for each entry in a second-level pop-up.  `r tufte::margin_note("Both function- and argument expansion also work in plain R, though you may have to hit the tab-key twice, and only the names (and not the help) are displayed.")` Furthermore, once you have typed or selected the function name with the trailing parentheses, you can move the cursor between these parentheses and hit the tabulator-key again to get a scrollable, reactive list of the function arguments (with documentation).


## Objects

While the arrow-key navigation of previous expressions is helpful, we do not want to re-calcuate the same expression repeatedly. Therefore, R allows you to store results as _objects_ under a freely chosen name: R saves a copy of the specified result in its memory, and from there on, you can use the name to refer to the result. 

To assign a _value_ to a chosen _name_ in R, you can use the operator `<-`:^[Note: you can also use a sinle equal sign, as in _name_ `=` _value_, though this is less common and potentially confusing]

_name_ `<-` _value_ 

Note that there are some limitations for object names: they can only contain letters, numbers, dots `.` and  underscores `_`, and they cannot start with a number.^[It is also generally a good idea to avoid non-ASCII characters like ä, å etc.] 


`r tufte::newthought("Example: objects")`

Let's define two objects called `a` and `A` that both store numerical results: 
```{r}
a <- 3 
A <- 3 + 1
```
In order to see the content of an object, you just type its name at the command prompt - to R, this is just another type of expression:^[Also, R clearly distinguishes between small `a` and capital `A` as two different objects, with different content.]
```{r}
a
A
```
In the same way, you can define objects that store the value of a character expression. Also, it can be helpful to have longer, more informative names for objects:
```{r, output = TRUE}
myWorkDir <- getwd()
myWorkDir
```
Note that this uses the function `getwd` from the previous example to return an informative character expression. The value of this function call is saved under the chosen object name, exactly as for the numerical expressions above.

What has happened with the previously defined objects? Nothing; they are around until further notice (see below), or until the user quits R. So you get the same value for object `a` as before:
```{r}
a
```

`r tufte::newthought("Managing objects")`

During a typical interactive session, you will generate a number of different objects, containing different types of data and results. In order to get an overview of what objects are currently defined (and therefore available for analysis and inspection), you can either check the Environment tab in RStudio, which shows a list of the currently defined objects, or run a command at the prompt:

\begin{marginfigure}
\centering 
\includegraphics[width=\textwidth]{figures/03_RStudio_EnvTab_list.png}\caption{RStudio Environment tab}
\end{marginfigure}

```{r}
ls()
```
Once an object is defined, it will stay defined and available at the command prompt for the rest of the R session. However, you can change the _content_ of the object through a new assignment to the same name:
```{r}
a <- 3.18
a
```
If you want to remove an object completely, so that its name is no longer defined, you can use the function `rm`:`r tufte::margin_note("The names \\texttt{rm} (for remove) and \\texttt{ls} (for list) are  taken from corresponding Unix shell commands for files")`
```{r, error=TRUE}
rm(a)
ls()
a
```
If not deleted, objects will stay in memory until the end of the R session; if not saved to disk when R shuts down, they will be lost (see below for shutting down R safely).

## All together now: general expressions

As you may have foreseen, you can combine simple expressions (with arithemtic- or comparison operators), functions and objects in a completely natural and flexible manner.

`r tufte::newthought("Example: general expressions")`
```{r}
a <- -1
x <- 3*sqrt(16) - abs(a)
x 
```

\newpage

# Working with data

## Basic data types 

The data type of an expression determines what kind of information has been collected or measured. We have already seen examples for three important data types, namely `numerical`, `character` and `logical`, corresponding to numerical, discrete and binary data, respectively. 

Here, I want to introduce a fourth data type, _factor_, for keeping track of discrete (grouping) data. This is similar to `character`, but has some advantages over `character` for statistical analysis and modelling. Data of other types (`numerical`, `character` etc.) can be converted manually to a `factor` using the function of the same name, but often this is done automatically when reading data into R from an external source like a file. I will show examples for both uses below. 


## Basic data structures

While a data type describes what a single item of information looks like, a _data structure_ describes how multiple items of information can be arranged and used together. This is of course crucial for any data analysis with $n>1$ samples, but has not been discussed so far. 

`r tufte::newthought("Linear structure: vector")`

The simplest data structure for multiple observations is linear, presenting measurements in order from first to last. Statistically, this corresponds to a study where you collect information on a single variable and in a single population. In R, this structure is known as a _vector_ (in other programming languages as a one-dimensional array). 

We can construct a vector manually at the command line, by using the function `c` (for _combine_) and listing all elements of the vector as arguments:
```{r}
c(2.57, 3.14, 3.78, 1.90, 2.45)
```
R just displays the elements of the vector in the given order. The same general rules apply for vectors as for other expressions, so you can e.g. save a vector as an object under a freely chosen name:
```{r}
x <- c(2.57, 3.14, 3.78, 1.90, 2.45)
x
```
You can also use the vector as argument to functions, e.g. for calculating basic descriptive statistics: function `mean` accepts a numerical vector with one or more elements, and returns a single number, the arithmetic mean of the elements of the argument. Function `sd` does the same for the standard deviation:
```{r}
mean(x)
sd(x)
```
In the same way, you can define character vectors for keeping track of non-numeric observations for a set of subjects, e.g. identifiers or group labels. A possible grouping variable for the same five subjects as above could be 
```{r}
grp <- c("case", "control", "control", "case", "control")
grp
```
Again, we can use functions to extract information from the vector, e.g. the frequency of the observed groups:
```{r}
table(grp)
```
As mentioned above, it is generally preferable to store grouping variables as factors instead of character strings, which is as easy as:
```{r}
grp2 <- factor(grp)
grp2
```
`grp2` has of course the same information about the five subjects, but note the differences in display: no quotation marks around the vector entries, and the _levels_ of the factor (the different values allowed) are displayed explicitly below the data. 

`r tufte::newthought("Rectangular structure: data frame")`

In the example above, you have constructed two vectors with information about five subjects, one with numeric measurements and one with grouping information. In a situation like this, where more than one variable is measured on a group of subjects, it is extremely useful to be able to save all that information as one object in R (instead of as a collection of unrelated vectors). This is the motivation for the default structure for data analysis, the _data frame_.

A data frame is a rectangular arrangement of information, where each row corresponds to a single subject under study, and each column to a single variable that is measured. A simple way to build such a data frame is to use the function `data.frame`. For the example above with five subjects and two variables, this could be
```{r}
dat <- data.frame(grp2, x)
dat
```
The data is displayed arranged as rows and columns, with the names of the vectors used as column names and a running number as row name. Object `dat` now contains all necessary information for a basic analysis, and is the only object you have to keep track of from here on. 

Importantly, a data frame is not a black box: you can still extract the information for individual processing. A simple way of extracting a variable is the `$`-notation:
```{r}
dat$grp
table(dat$grp)
dat$x
mean(dat$x)
```

In short, a data frame is the R implementation of the standard format for analysis data in statistical software, the data matrix, given as subject rows $\times$ variable columns.^[Note that the convention is different in e.g. bioinformatics, where generally rows correspond to features (variables), and columns to samples (subjects). This is the source of much hilarious confusion.]


## Getting data into R

Building a data frame from hand at the command prompt is neither usual nor recommended. The most common way to import rectangular data into R for analysis is to read it from an external file. With add-on packages, R can read (and often write) a large number of formats, including data files from Stata or SAS as well as Microsoft Excel formats. Import functions of this type generally take as argument the name of the file to be read, and return as result a data frame with its content.^[Import functions also generally have a large number of optional arguments that allow fine control over how the data is read; see e.g. ?read.table]

In base R, `read.table` can read data from a wide range of delimited text formats.
\begin{marginfigure}
\centering 
\includegraphics[width=\textwidth]{figures/04_RStudio_EnvTab_import.png}\caption{RStudio Environment with import menu}
\end{marginfigure}
The `Environment`-pane offers shortcuts for importing other types of common data files.


`r tufte::newthought("Example: qPCR data")`

This document comes with a data set `qPCR.txt` that contains the results of a small qPCR experiment, where the expression of a target gene in treated _Arabidopsis thaliana_ plants was compared to untreated controls plants, at four different concentrations, each with three replicates.^[[PMC1395339](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1395339/#T1)] Consequently, the file contains 24 measurements of the relative expression level of the target gene compared to a reference gene (`DeltaCt`), together with the corresponding treamtent status (`Sample`) and concentration (`Con`); variable names are listed in the first row of the file.

We use `read.table` to import this data, which we directly save as object `ex1`. The argument `header=TRUE` tells `read.table` to use the first row as column names, and the argument `stringsAsFactors = TRUE` to import the character column directly as a factor variable:
```{r, R.options = list(width = 60), echo = FALSE}
code <- paste0("ex1 <- read.table(\"",.trueDir, "/Data/qPCR.txt\", header = TRUE, stringsAsFactors = TRUE)")
eval(parse(text = code))
code <- sub(.trueDir, .showDir, code)
code <- strwrap(code, width = 60, prefix = "", initial = "")
cat(paste0(code, "\n"))
```


## Inspecting data

I recommend some basic quality checks after each data import. We can use the function `head` to display the first few rows of the data:
```{r}
head(ex1)
```
The data looks ok, and the column names were properly imported as variable names.

More formally, we can use the function `str` to look at the _structure_ of the object `ex1`:
```{r}
str(ex1)
```
\begin{marginfigure}
\centering 
\includegraphics[width=\textwidth]{figures/05_RStudio_EnvTab_structure.png}\caption{RStudio Environment tab also showing the structure of ex1}
\end{marginfigure}
This is quite informative: we learn that this is indeed a data frame with 24 rows and three columns, all of which have the right type and name, and the values appear to be correct, too.^[And the grouping variable Sample was indeed automatically converted to a factor variable by read.table]

Everything used in the small $5\times 2$ toy example above works here, too, including the `$`-notation:
```{r, R.options = list(width = 60)}
ex1$Del
```
Note that we only have to type enough of the column name to uniquely identify the variable.^[This is actually quite lazy, as both R and RStudio support tab-expansion for column names.]

\newpage

# Workflow

Let's put all parts together to look at a standard situation: you have some data in a file, which you want to analyse; the results from this analysis are to be included in a report. For this exercise, let's use the qPCR data from before to demonstrate how this can be done in R. 

I suggest breaking down the workflow as follows:

1. Prepare by putting the data file(s) into a folder on the harddisk that is easy to find & access. 

2. Start R/RStudio

3. Set the working directory & load the data

4. Run some descriptives: this includes calculating descriptive statistics like mean or standard deviation, as well as plotting the data. Descriptives can be a simple quality control, or they may be included in the report.

5. Run the analysis: the main analysis of interest, generally involving some statistical inference (estimates, confidence intervals, p-values).

6. Export results: extract the numerical and graphical output you want to include in the report.

7. Shut down R/RStudio: this requires a decision whether to save the R objects generated during the workflow.

## Finding & loading data

As demonstrated above, you can specify the full path to any file on the harddisk for reading it in via `read.table`. However, I recommend setting R's default directory, the _working directory_, right at the start of the analysis. This makes it easier to keep track of files that you generate while working with this specific data.

The working directory can be set at the command prompt:
```{r}
setwd(.trueDir)
dir()
```
Note that my working directory has a number of sub-folders, which is generally a good idea if your project involves more than a handful of files.

After setting the working directory, all further file operations that do not explicitly start at the root of the file system will be _relative_ to the working directory. So in order to read the file `qPCR.txt` in sub-folder `Data`, it is sufficient to run^[Another round of tab-expansions: once you have placed the cursor between the quotation marks, you can start to type the file name, and hit tab to show a list of available files in the working directory.]
```{r}
ex1 <- read.table("Data/qPCR.txt", header=TRUE,
                  stringsAsFactors = TRUE)
str(ex1)
```
Alternatively, you can use the GUI to set the working directory: both R and RStudio have menu items for that (`File/Change dir` and `Session/Set working dir`, respectively). RStudio also offers the Files pane, where you can explore the directory tree interactively to set a working directory.

\begin{marginfigure}
\centering 
\includegraphics[width=\textwidth]{figures/06_RStudio_FilesTab.png}\caption{RStudio Files pane}
\end{marginfigure}


## Descriptive statistics

A useful function for generic descriptives is `summary`: if the argument is a numerical vector, it will display a number of location measures (minimum, maximum, mean, median and the first and third quartile); if the argument is a factor vector, the function will return a frequency table. Conveniently, when the argument is a data frame, it will return a summary for each variable, depending on type: 
```{r, R.options = list(width = 75)}
summary(ex1)
```
This can be combined with other summary statistics of interest, like `sd` for standard deviations and `IQR` for the interquartile range. 
 
## Plots

R has a very rich set of graphical functions, including three independent systems for generating high-level plots. The examples shown here are from the oldest system, the _base graphics_, which is directly available in R.^[The other two systems are ggplot2 and lattice, respectively. Both require that an add-on package of the same name is installed and loaded.]

The function `hist` takes a numerical vector as argument and draws a histogram in the current plotting window:
```{r, fig.margin = TRUE, fig.cap = 'Histogram of DeltaCt', fig.width=3.5, fig.height=3.5}
hist(ex1$DeltaCt)
```

\newpage

The function `boxplot` can draw boxplots of values of a given variable for separate groups of subjects, given by another variable. This draws separate boxplots for the relative strength of gene expression `DeltaCt` for the two groups of measurements as seen in grouping variable `Sample`:
```{r, fig.margin = TRUE, fig.cap = 'Boxplot of DeltaCt by group', fig.width=3.5, fig.height=3.5}
boxplot(DeltaCt ~ Sample, data = ex1)
```
The first argument in this function call is a _formula_, an R construction that is widely used for specifying e.g. plots and regression models; the tilde character `~` is best read "as a function of", so here "plot `DeltaCt` as a function of `Sample`" (where both variables are taken from the data frame `ex1`, as specified by the second argument).

With regard to the plot itself, we see that the expression levels are clearly higher among controls than among cases, and that there is a suspiciously large value among the controls - interesting for the report?

Base graphics look a rather old-fashioned, but are straightforward to create, and can be prettified in many ways, using titles, labels, colors, fonts etc., all of which goes beyond the scope of this document.

## Statistical tests

For the current example, a simple t-test for the null hypothesis that the mean gene expression level (averaged across all concentrations) is the same for both treated plants and untreated controls seems a reasonable sort of inference. This can be done via the function `t.test`: 

```{r, include=FALSE}
## Ok, so this is horrible:
## * I override the default t.test function with a wrapper that changes the class to "htest2"
## * I define a print method for that class that breaks the alt.hyp. string as required
## * Let nature take its course
##
## THIS USED TO WORK OUT OF THE BOX, see version 2020
##
## Nothing else has worked: 
## - print.htest does no longer (?) respect width for alt. hyp.
## - Using a combined eval = -, echo = 1 to just override the output shows the 
##   t.test as commented
## - I did not manage to override the source hook as shown e.g. 
##   https://bookdown.org/yihui/rmarkdown-cookbook/output-hooks.html
##
## I sincerely apologize for the hack FIXME
t.test <- function(...) {ret <- stats::t.test(...); class(ret) <- "htest2"; ret} 
print.htest2 <- function(x){
  tt    <- capture.output(stats:::print.htest(x))
  tt[6] <- paste(strwrap(tt[6], width=68, exdent = 2), collapse = "\n")
  cat(tt,  sep = "\n")
}
```
```{r}
t.test(DeltaCt ~ Sample, data = ex1)
```               
```{r, include = FALSE}
rm(t.test); rm(print.htest2)
```               

The function call and the result for this test are very similar to most other basic tests, so let's have a look:

* The outcome and grouping variable as well as the data frame where they live are specified as before via a formula.
* The first row of the output states the test used: here, the Walch t-test, which does not assume equal variances between groups (but which the Student t-test does).
* This is followed by information on the data used, the test statistic, and the p-value for the null hypothesis; here, a p-value of less than 3.5E-5 indicates that the difference is statistically significant at most conventional significance levels. 
* The test does not state the null hypothesis, but the alternative hypothesis: here, a simple two-sided alternative, i.e. we reject the null hypothesis of equal means for both large negative and large postive mean differences.
* This is followed by a number of descriptive statistics, here: a 95% confidence interval for the mean difference between groups, and the respective group means. 

The results here are very similar to the results in Table 3 of the original publication (and would be identical if we had chosen the Student t-test instead of Walch.)


## Export results

Results to be included in a report can be exported manually: text output can be selected in the console, copied to the clipboard, and pasted into the target document. Graphs can be extracted via the `Export`-menu in the plot tab, and either be saved to an image file, or again copied to the clipboard.^[In base R, the same functionality is available via right-clicking the plot window] 

Manual export / copying and pasting is reasonably fast and convenient for a few numbers and plots, but generally not recommended, because it breaks the connection between the R code use to generate the results and the results themselves: this is a common source of errors that is hard to track. It also has to be repeated whenever the data or the analysis changes, and formatting even moderately large result tables becomes very time consuming.

Therefore, results should generally be exported as part of an analysis script that automates both analysis and extraction of the desired results, see R Scripts below.

\begin{marginfigure}
\centering 
\includegraphics[width=\textwidth]{figures/07_RStudio_PlotTab_Export.png}\caption{RStudio Files pane}
\end{marginfigure}


## Shut down R

Terminating an R session is easy: select the `Quit`-entry in the `File`-menu, or kill the program window, or use the command `q()` in the console. 
\begin{marginfigure}
\centering 
\includegraphics[width=\textwidth]{figures/08_RStudio_Quit.png}\caption{R Quit dialogue}
\end{marginfigure}
However, by default, all data, results, and plots generated during an R/RStudio session will be lost when quitting R, unless you take steps to save them for later. Therefore, by default, R will always offer to save the _workspace image_ when you quit a session: this means that all currently defined objects will be saved to a file called `.RData` in the current working directory. This file can later be loaded via the `Load workspace`-entry in the `Session`-menu.^[In base R, in the File-menu], or via the `load()` command in the console.^[If the current working directory is also the start-up directory for R/RStudio, this .RData file will be loaded automatically at the start of the next session, with a message in the console.]

Note that you can save the current workspace image at any time via the `Environment`-tab or the `save.image()`-command.

In addition, RStudio will also save all the R commands used in the current R session (as seen in the `History`-pane) to a file `.Rhistory` in the current working directory.^[By default, RStudio will always save the history, but base R only when also saving the workspace image.] This is a simple text file that can be opened in any text editor, or re-loaded into R via the `History`-pane or the `loadhistory()`-command. 

\newpage

# Adding functionality with R packages

## Background

R supports a mechanism through which user-written software can be distributed and used in (almost) the same manner as the commands built into R: _R packages_. These packages are written using R commands, similar to the R scripts discussed below, but may also include code from other programming languages like e.g. C++. While R is a powerful statistical package in its own right, it is the huge collection of R packages that contribute the majority of methods available through R. 

Packages are mostly available through curated online collections, i.e. _repositories_:

\begin{marginfigure}
\centering 
\includegraphics[width=\textwidth]{figures/10_CRAN_web.png}\caption{CRAN \url{https://cran.r-project.org/}}
\end{marginfigure}    

1. The most important and default repository is CRAN, the Comprehensive R Archive Network, with currently more than 18,000 packages covering an extremely wide range of applications. 

2. Bioconductor is another large (currently more than 2,000 packages) collection, focused on high-throughput genomic data.

\begin{marginfigure}
\centering 
\includegraphics[width=\textwidth]{figures/11_Bioconductor_web.png}\caption{Bioconductor \url{https://www.bioconductor.org/}}
\end{marginfigure}



The curation process for these repositories ensures minimal standards of software quality and documentation. Other sources which also host many R packages for download, like github^[[github.com/topics/r?l=r](https://github.com/topics/r?l=r)], lack these standards, leading to more variable package quality. 

## Installation vs Loading

In order to make use of the commands and data sets in an R package, two steps are necessary:

1. The package needs to be _installed_: this means that there has to be a local copy of the data and software on a file path known to R. Packages available on CRAN can be downloaded via the command `install.packages`, e.g. as in 

    ```{r, eval = FALSE}
    install.packages("ggplot2")
    ```
    
    Note that installation is only required _once_: after the package has been installed, the local copy remains on the local hard disk for all future R sessions.  
    
2. The package needs to be _loaded_: this tells R to activate the installed copy of the package and make its built-in commands and data sets available at the console. This is done via the command `library`, as in 

    ```{r, eval = FALSE}
    library(ggplot2)
    ```
    
    Note that loading is required _once per session_, namely the first time before you use one of the package commands or data sets; after the package has been loaded as above, it stays activated until the end of the R session. 

Installation and loading of packages can also be done via the `Packages`-pane in RStudio: this tab lists all installed packages currently installed, which can simply be loaded via checking their selection box. Extra packages can be installed via the `Install`-dialogue in this pane.  

\begin{marginfigure}
\centering 
\includegraphics[width=\textwidth]{figures/09_RStudio_PackagesTab.png}\caption{RStudio Package pane}
\end{marginfigure}

\begin{marginfigure}
\centering 
\includegraphics[width=\textwidth]{figures/12_RStudio_PackagesTab_Install.png}\caption{RStudio Package pane with Install dialogue}
\end{marginfigure}


## Example packages

Widely used packages include e.g.:

* `ggplot2`, a complete and modern plotting system 
* `dplyr`, offering consistent data manipulation (SQL-style)
* `data.table` implements a high-performance alternative to data frames for large data sets.

A popular package that provide useful tools for multivariate data and is available from CRAN:

* `factoextra`: data reduction methods (e.g. principal components) and visualizations

Other popular packages for bioinformatics-type data, available from Bioconductor:

* `limma` allows fitting of linear models for many features in parallel
* `biomaRt` interfaces to online repositories for feature annotation

Note that Bioconductor packages have a different installation process, demonstrated on the respective package homepages. 

## Finding more useful packages

As it is often difficult identify just the right package required for a task simply through search engines, both CRAN and Bioconductor offer curated lists of packages that can be used for specific application areas:

* For CRAN, these are _task views_^[[cran.r-project.org/web/views/](https://cran.r-project.org/web/views/)]

* For BioConductor, these are _BioCViews_^[[www.bioconductor.org/packages/release/ BiocViews.html#___Workflow](https://www.bioconductor.org/packages/release/BiocViews.html#___Workflow)], which organize packages hierarchically by application, domain, method etc., e.g. packages useful within metagenomics^[[www.bioconductor.org/packages/release/ BiocViews.html#___Metagenomics](https://www.bioconductor.org/packages/release/BiocViews.html#___Metagenomics)]   


\newpage

# Building a simple script

R/RStudio make it very easy to translate an interactive data analysis into an _analysis script_: this is simply a text file containing a series of R commands that act together to achieve some goal, e.g. clean a data set, fit a regression model, create a plot etc. 

## Why scripts?

The main reason is **replicability**: given the original data and the corresponding analysis script, anyone (including yourself) can replicate the intended analysis. Given only the data and the analysis results, this is generally not possible. 

Scripts have a number of other important practical advantages: a script can be

* _documented_, making it easy to understand how and why an analysis was performed, and how to interpret the results;
* _modified_: if the data changes, or if the analysis needs to be expanded, the relevant parts can be edited, and the modified script can be re-run;
* used to generate _draft reports_ that contain all results and graphs.


## Building a script

\begin{marginfigure}
\centering 
\includegraphics[width=\textwidth]{figures/13_RStudio_HistoryTab.png}\caption{RStudio History pane showing the workflow example}
\end{marginfigure}

It is easiest to start with an interactive analysis, e.g. by running a workflow as described in the previous section.

All commands used in an interactive session are shown in the **History** tab. From there, some or all of the commands can be selected and copied to a text file via the `To Source`-button. 
\begin{figure*}
\centering 
\includegraphics[width=\textwidth]{figures/14_RStudio_wSourcePane.png}\caption{RStudio with open Source pane showing script script1.R\label{fig:Source}}
\end{figure*}

This text file is then opened in the **Source**-pane of RStudio, which is an integrated multi-tabbed text editor with special support for editing and running R script files, as seen in Figure \ref{fig:Source}:

* tab-expansion for R functions, function arguments and file names works,
* some or all of the commands can be selected and run at the console, either via the `Run`-Button at the top of the editor pane, or by pressing `Ctrl-Return`at the same time.

Once the newly generated R script with the recycled commands has been generated, it should be save directly under a suitable file name with the extension `.R`. 

## Adding comments

Comments are text in the script that is ignored when the commands are run: this is information that helps the person reading, editing or running the script to understand what it does, and how it does it. Comments provide context and are crucial making an analysis script _easily_ replicable and modifiable. 

Note that the person that will read, edit etc. the script and needs to understand it may be an internal or external collaborator, but is most likely _yourself in six months_: writing good comments means that you are making your own life easier. 

Comments are easy to add: R/RStudio will ignore any text after a hashtag `#` until the end of the current line.

Personally, I always include the filename, a short description, my email address and the original date of writing in any R script I save; I also add comments to separate major steps in the workflow, like setup, data import, data cleaning etc. and explain anything unusual or smart I have done in the code (see e.g. the script files included with this document).

## Running  a script

A saved R script can always be opened in RStudio (as a tab in the editor pane), the code selected and run via the `Run`-button. Alternatively, the whole script (from first to last command) can be run via the `Source`-menu, or the `source`-command in the console. 

## From script to draft report

In you have opened an R script in the editor pane, you can translate it into a draft report by clicking the _Compile report_-button  ^[\raisebox{-.5\height}{\includegraphics[width=0.1\textwidth]{figures/CompileReport.png}}] at the top of the pane. This allows you choose an output format ((HTML, PDF, Word), and will then 

* run all commands in the script,
* collect all output generated by these commands, both graphical and numerical,
* combine all the comments, code and results in one document,
* convert that document to the chosen format. 

This draft output can then be edited to generate a full report on the data analysis:

\begin{figure}
\centering 
\includegraphics[width=\textwidth]{figures/16_Compiled_Script1_Word.png}\caption{Compiled Script1.R as Word file}
\end{figure}

This technique can be greatly expanded to generate e.g. nicely formatted reports directly from script files, see e.g. package `knitr`^[[yihui.org/knitr/](https://yihui.org/knitr/)]. 


# Other Resources

* CRAN user contributed documentation of varying length^[[cran.r-project.org/other-docs.html](https://cran.r-project.org/other-docs.html)]
* RStudio cheatsheets: 1-page summaries on how to use RStudio, specific packages, or perform specific packages^[[https://posit.co/resources/cheatsheets/](https://posit.co/resources/cheatsheets/)]
* Bioconductor common workflows show how Bioconductor packages can work together^[[bioconductor.org/packages/release/workflows/](http://bioconductor.org/packages/release/workflows/)]
* Bioconducor user-contributed documentation^[[http://bioconductor.org/help/community/](http://bioconductor.org/help/community/)]
* Bioconductor course material^[[bioconductor.org/help/course-materials/](http://bioconductor.org/help/course-materials/)]
* Bioconductor featured publications^[[bioconductor.org/help/publications/index.html](http://bioconductor.org/help/publications/index.html)]
