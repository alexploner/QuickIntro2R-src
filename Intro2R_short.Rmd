---
title: "Introduction to R/RStudio"
author: "Alexander Ploner"
date: "2020-11-19"
output:
  tufte::tufte_handout:
    highlight: default
classoption: a4paper  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, prompt = TRUE, comment = NA, collapse = TRUE)
knitr::opts_knit$set(root.dir = "Z:/@ownCloudKI/OmicsDataAnalysis/")
#knitr::opts_knit$set(root.dir = "~/@ownCloudKI/OmicsDataAnalysis/")
```

# This document

This is a short introduction to working with R/RStudio, covering the basics of working with the commandline, data types and data structures, and organising a simple analysis workflow. No previous exposure to R or RStudio is assumed. I strongly recommend that as a first-time reader, you work through the examples shown in the text at a computer. 

# Background

R is a free software environment for statistical computing and graphics^[[www.r-project.org](https://www.r-project.org/)]. Specifically, R is 

1. a program for statistical data analysis. Compared to software with similar functionality, R has a strong focus on interactive analysis (unlike the typical batch analysis in SAS) at a command prompt (unlike the graphical user interface of SPSS). 

2. a general-purpose programming language. R is an interpreted language (like Python, and unlike C or C++). Essentially, any kind of data handling or -analysis method can be implemented in R. This also means that existing methods can be combined into complex analysis workflows through R script files. 

3. the infrastructure for a large number of add-on packages that implement methods in statistics, data processing, bioinformatics, machine learning and many other disciplines.^[[cran.r-project.org/web/packages](https://cran.r-project.org/web/packages/)] ^[[www.bioconductor.org/packages](https://www.bioconductor.org/packages)] 

\begin{figure}
\centering 
\includegraphics[width=\textwidth]{figures/Rgui_3_6_1_Windows10.png}\caption{The main R window, showing the console with the start-up message and the command prompt.}
\end{figure}


RStudio is an integrated development environment built on top of R. It provides a graphical user interface around the R console, including a code editor, a file browser, a help viewer, a tab for local data management and other utilities. In principle, all of this functionality is also available in R via commands and add-on packages, but the clean structure and tight integration of RStudio makes the learning process easier for most beginners. RStudio has an additional focus on data science and related software development, some aspects of which can be generally useful for data analysis (e.g. version control integration via git, svn), whereas others are more developer-oriented (e.g. javascript-intergration via shiny).

Both R and RStudio are open source software, and freely available online^[Installers can be run with defaults.], but where R is community-developed and non-profit^[[www.r-project.org/foundation/](https://www.r-project.org/foundation/)], RStudio is the product of a commercial entity^[[linkedin.com/company/rstudio-inc](https://www.linkedin.com/company/rstudio-inc)].

\begin{figure}
\centering 
\includegraphics[width=\textwidth]{figures/RStudio_1_2_5001_Windows10.png}\caption{The RStudio window showing three different panels: the large panel to the left is the console, identical in look and function to the R console above. The top right panel shows the current R environment, which is still empty after start-up (no objects defined). The bottom right panel shows the files in the current working directory.}
\end{figure}

\newpage

# Working interactively

## At the prompt

The basic workflow for interactive data analysis looks like this:

1. Start RStudio

2. In the console pane (at the command prompt `>`), a steady loop:`r tufte::margin_note("Note: you can browse through previous input via arrow keys, edit and re-use it. This minimzes typing and allows for rapid incremental refinement of the analysis.")`

    * Type input (**expression**, see below), hit return
    * R evaluates input and displays result (text output, plot)
    * Based on results, provide new input (expression) 

3. Quit (and save, if necessary)

## Simple expressions

At the most basic level, R can work as a glorified calculator for numerical expressions that consist simply of numbers and basic arithmetic operations:^[Text after the prompt > is typed by you, text below, usually starting with [1], is output generated by R.]
```{r}
3
3+4*2
```
R also uses character expressions (strings), e.g. to keep track of group identifiers in data or to define labels for plotting. Character values are enclosed in single `'` or double `"` quotation marks:
```{r}
"My name is"
'Earl'
```
R also uses logical (or boolean) expressions, e.g. to select subsets of data or to test for conditions. These expressions have only two possible values, `TRUE` and `FALSE`. We can use comparison operations on numbers or characters (as well as other data types) to create logical expressions: 
```{r}
TRUE
3 < 4
"Earl" == "earl"
```

## Functions

Everything interesting in R is done via _functions_. These are small, pre-packaged pieces of code that can perform a specific task. Functions have names (generally), and zero, one or more _arguments_, i.e. slots for pieces of information that the function either operates upon (data), or that tell the function what to do (flags, parameters). 

In order to run (execute) a function, you type its name at the console, followed by a pair of parentheses with the arguments for what you want the function to do, separated by commas.

`r tufte::newthought("Example: functions")`

The function `sqrt` calculates the square root. It takes one numerical argument, and returns one numerical value, which is the desired result:
```{r}
sqrt(4)
```
The function `paste` takes two or more character arguments, and returns one character result, which is just the joined arguments, separated by an empty space:
```{r}
paste("My name is", "Earl")
```
The function `log` calculates by default the natural logarithm (for base $e$). Like the square root, it takes one numerical argument, and returns the numerical result:
```{r}
log(10)
```
However, `log` has a second argument, called `base`, which you can use to specify a different base for the logarithm. So you can calculate the common logarithm (for base 10) and the binary logarithm (for base 2) like this:
```{r}
log(10, base = 10)
log(10, base = 2)
```
The function `getwd` takes no arguments, and returns a string with the current working directory, which is the path to the directory (folder) where R by default reads and writes files^[Note: R uses slashes (`/`) not backslashes (`\\`) for separating file- and folder names in a path.]:
```{r}
getwd()
```
Note that you still need to add an (empty) pair of parentheses to indicate that you want the function to run, even though no argument is given.

The functions in the examples so far do their job by returning a numerical or string result. This is the most common way to work with functions in R: you feed some data to a function, which returns a result, which you then can feed into another function, and so on. In some situations however, you want a function to simply _do_ something, e.g. create a plot or write data to a file^[This is generally described as the function being run for its _side effect_. This is somewhat misleading, as this is often the only thing you are interested in.] An example for this kind of function is `browseURL`, which takes a character argument with the URL we want to visit, and opens the default browser on your system pointed at that address:
```{r, eval=FALSE}
 browseURL("https://cran.r-project.org")
```

`r tufte::newthought("Finding functions")`

The functions in the examples above are all part of base R, and are immediately available at the command prompt after starting R/RStudio. Most other functions however live in specialized add-on packages, which need to be loaded before you can use their functions; see ??? for details.

Learning how to use functions, and what functions to use in order to get a task done, is the hardest part when starting with R. To help you with this, R and its add-on packages have large amounts of documentation available. In the simplest case, when you remember the name of the function, you can just type 
```{r, eval=FALSE}
?t.test
```
at the command line; this will open the corresponding documentation in a separate window. 

\begin{marginfigure}
\centering 
\includegraphics[width=\textwidth]{figures/RStudio_1_2_5001_Windows10_Help_ttest.png}\caption{RStudio Help tab}
\end{marginfigure}

If you only kind of remember the name of the function, say something with "test", you can type `r tufte::margin_note("Note: \\texttt{apropos} is again just an R function, which takes a character expression with the string of interest as argument, and returns a series of character expressions, which are the names of the functions that match the string.")`
```{r, eval=FALSE}
apropos("test")
```
to list all currently aviable functions with "test" in their name. 

A very useful feature is also _tab-expansion_: when typing the function name in RStudio, hitting the tabulator-key will open a context menu at the cursor that lists all available function names that complete the already typed text; this list is scrollable, reactive (i.e. more typing narrows the list), and displays the help text for each entry in a second-level pop-up.  `r tufte::margin_note("Both function- and argument expansion also work in plain R, though you may have to hit the tab-key twice, and only the names (and not the help) are displayed.")` Furthermore, once you have typed or selected the function name with the trailing parentheses, you can move the cursor between these parentheses and hit the tabulator-key again to get a scrollable, reactive list of the function arguments (with documentation).


## Objects

While the arrow-key navigation of previous expressions is helpful, we do not want to re-calcuate the same expression repeatedly. Therefore, R allows you to store results as _objects_ under a freely chosen name: R saves a copy of the specified result in its memory, and from there on, you can use the name to refer to the result. 

To assign a _value_ to a chosen _name_ in R, you can use the operator `<-`:^[Note: you can also use a sinle equal sign, as in _name_ `=` _value_, though this is less common and potentially confusing]

 _name_ `<-` _value_

Note that there are some limitations for object names: they can only contain letters, numbers, dots `.` and  underscores `_`, and they cannot start with a number.^[It is also generally a good idea to avoid non-ASCII characters like ä, å etc.] 


`r tufte::newthought("Example: objects")`

Let's define two objects called `a` and `A` that both store numerical results: 
```{r}
a <- 3 
A <- 3 + 1
```
In order to see the content of an object, you just type its name at the command prompt - to R, this is just another type of expression:^[Also, R clearly distinguishes between small `a` and capital `A` as two different objects, with different content.]
```{r}
a
A
```
In the same way, you can define objects that store the value of a character expression. Also, it can be helpful to have longer, more informative names for objects:
```{r}
myWorkDir <- getwd()
myWorkDir
```
Note that this uses the function `getwd` from the previous example to return an informative character expression. The value of this function call is saved under the chosen object name, exactly as for the numerical expressions above.

What has happened with the previously defined objects? Nothing; they are around until further notice (see below), or until the user quits R. So you get the same value for object `a` as before:
```{r}
a
```

`r tufte::newthought("Managing objects")`

During a typical interactive session, you will generate a number of different objects, containing different types of data and results. In order to get an overview of what objects are currently defined (and therefore available for analysis and inspection), you can either check the Environment tab in RStudio, which shows a list of the currently defined objecsts, or run a command at the prompt:

\begin{marginfigure}
\centering 
\includegraphics[width=\textwidth]{figures/RStudio_1_2_5001_Windows10_EnvTab.png}\caption{RStudio Environment tab}
\end{marginfigure}

```{r}
ls()
```
Once an object is defined, it will stay defined and available at the command prompt for the rest of the R session. However, you can change the _content_ of the object through a new assignment to the same name:
```{r}
a <- 3.18
a
```
If you want to remove an object completely, so that its name is no longer defined, you can use the function `rm`:`r tufte::margin_note("The names \\texttt{rm} (for remove) and \\texttt{ls} (for list) are  taken from corresponding Unix shell commands for files")`
```{r, error=TRUE}
rm(a)
ls()
a
```
If not deleted, objects will stay in memory until the end of the R session; if not saved to disk when R shuts down, they will be lost (see below for shutting down R safely).

## All together now: general expressions

As you may have foreseen, you can combine simple expressions (with arithemtic- or comparison operators), functions and objects in a completely natural and flexible manner.

`r tufte::newthought("Example: general expressions")`
```{r}
a <- -1
x <- 3*sqrt(16) - abs(a)
x 
```

\newpage

# Working with data

## Basic data types 

The data type of an expression determines what kind of information has been collected or measured. We have already seen examples for three important data types, namely `numerical`, `character` and `logical`, corresponding to numerical, discrete and binary data, respectively. 

Here, I want to introduce a fourth data type, _factor_, for keeping track of discrete (grouping) data. This is similar to `character`, but has some advantages over `character` for statistical analysis and modelling. Data of other types (`numerical`, `character` etc.) can be converted manually to a `factor` using the function of the same name, but often this is done automatically when reading data into R from an external source like a file. I will show examples for both uses below. 


## Basic data structures

While a data type describes what a single item of information looks like, a _data structure_ describes how multiple items of information can be arranged and used together. This is of course crucial for any data analysis with $n>1$ samples, but has not been discussed so far. 

`r tufte::newthought("Linear structure: vector")`

The simplest data structure for multiple observations is linear, presenting measurements in order from first to last. Statistically, this corresponds to a study where you collect information on a single variable and in a single population. In R, this structure is known as a _vector_ (in other programming languages as a one-dimensional array). 

We can construct a vector manually at the command line, by using the function `c` (for _combine_) and listing all elements of the vector as arguments:
```{r}
c(2.57, 3.14, 3.78, 1.90, 2.45)
```
R just displays the elements of the vector in the given order. The same general rules apply for vectors as for other expressions, so you can e.g. save a vector as an object under a freely chosen name:
```{r}
x <- c(2.57, 3.14, 3.78, 1.90, 2.45)
x
```
You can also use the vector as argument to functions, e.g. for calculating basic descriptive statistics: function `mean` accepts a numerical vector with one or more elements, and returns a single number, the arithmetic mean of the elements of the argument. Function `sd` does the same for the standard deviation:
```{r}
mean(x)
sd(x)
```
In the same way, you can define character vectors for keeping track of non-numeric observations for a set of subjects, e.g. identifiers or group labels. A possible grouping variable for the same five subjects as above could be 
```{r}
grp <- c("case", "control", "control", "case", "control")
grp
```
Again, we can use functions to extract information from the vector, e.g. the frequency of the observed groups:
```{r}
table(grp)
```
As mentioned above, it is generally preferable to store grouping variables as factors instead of character strings, which is as easy as:
```{r}
grp2 <- factor(grp)
grp2
```
`grp2` has of course the same information about the five subjects, but note the differences in display: no quotation marks around the vector entries, and the levels of the factor (the different values allowed) are displayed explicitly below the data. 

`r tufte::newthought("Rectangular structure: data frame")`

In the example above, you have constructed two vectors with information about five subjects, one with numeric measurements and one with grouping information. In a situation like this, where more than one variable is measured on a group of subjects, it is extremely useful to be able to save all that information as one object in R (instead of as a collection of unrelated vectors). This is the motivation for the default structure for data analysis, the _data frame_.

A data frame is a rectangular arrangement of information, where each row corresponds to a single subject under study, and each column to a single variable that is measured. A simple way to build such a data frame is to use the function `data.frame`. For the example above with five subjects and two variables, this could be
```{r}
dat <- data.frame(grp2, x)
dat
```
The data is displayed arranged as rows and columns, with the names of the vectors used as column names and a running number as row name. Object `dat` now contains all necessary information for a basic analysis, and is the only object you have to keep track of from here on. 

Importantly, a data frame is not a black box: you can still extract the information for individual processing. A simple way of extracting a variable is the `$`-notation:
```{r}
dat$grp
table(dat$grp)
dat$x
mean(dat$x)
```

In short, a data frame is the R implementation of the standard format for analysis data in statistical software, the data matrix, given as subject rows $\times$ variable columns.^[Note that the convention is different in e.g. bioinformatics, where generally rows correspond to features (variables), and columns to samples (subjects). This is the source of much hilarious confusion.]


## Getting data into R

Building a data frame from hand at the command prompt is neither usual nor recommended. The most common way to import rectangular data into R for analysis is to read it from an external file. With add-on packages, R can read (and often write) a large number of formats, including data files from Stata or SAS as well as Microsoft Excel formats. Import functions of this type generally take as argument the name of the file to be read, and return as result a data frame with its content.^[Import functions also generally have a large number of optional arguments that allow fine control over how the data is read; see e.g. ?read.table]

In base R, `read.table` can read data from a wide range of delimited text formats^[This is not a great limitation, as text-based data formats are the fall-back option for data exchange, supported by all reasonable data analysis software, as well as Microsoft Excel.] (which includes tab-delimited and CSV).  

`r tufte::newthought("Example: qPCR data")`

This document comes with a data set `qPCR.txt`^[link?!] that contains the results of a small qPCR experiment, where the expression of a target gene in treated _Arabidopsis thaliana_ plants was compared to untreated controls plants, at four different concentrations, each with three replicates.^[[PMC1395339](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1395339/)] Consequently, the file contains 24 measurements of the relative expression level of the target gene compared to a reference gene (`DeltaCt`), together with the corresponding treamtent status (`Sample`) and concentration (`Con`); variables names are listed in the first row of the file.

We use `read.table` to import the data file, which we directly save as object `ex1`. The argument `header=TRUE` tells `read.table` to use the first row as column names:
```{r, eval=1}
ex1 <- read.table("Z:/OmicsDataAnalysis/Data/qPCR.txt", header = TRUE)
#ex1 <- read.table("~/@ownCloudKI/OmicsDataAnalysis/Data/qPCR.txt", header = TRUE)
ex1
```

## Inspecting data

It is highly recommended to perform a basic quality check after each data import. At the command prompt, we can use the function `head` to display the first few rows of the data frame:
```{r}
head(ex1)
```
The data looks ok, and the column names were properly imported as variable names.

More formally, we can use the function `str` to look at the _structure_ of the object `ex1`:
```{r}
str(ex1)
```
This is quite informative: we learn that this is indeed a data frame with 24 rows and three columns, all of which have the right type and name, and the values appear to be correct, too.^[And the grouping variable Sample was indeed automatically converted to a factor variable by read.table]

Everything used in the small $5\times 2$ toy example above works here, too, including the `$`-notation:
```{r, R.options = list(width = 80)}
ex1$Del
```
Note that we only have to type enough of the column name to uniquely identify the variable.^[This is actually quite lazy, as both R and RStudio support tab-expansion for column names.]

\newpage

# Workflow

Let's put all parts together to look at a standard situation: you have some data in a file, which you want to analyse; the results from this analysis are to be included in a report. For this exercise, let's use the qPCR data from before to demonstrate how this can be done in R. 

I suggest breaking down the workflow as follows:

1. Prepare: put the data file(s) into a folder on the harddisk that is easy to find & access. 

2. Start R/RStudio

3. Set the working directory, load the data

4. Run some descriptives: this includes calculating descriptive statistics like mean or standard deviation, as well as plotting the data. Descriptives can be a simple quality control of the data, or they may be included in the report.

5. Run the analysis: the main analysis of interest, generally involving some statistical inference (estimates, confidence intervals, p-values).

6. Export results: extract the numerical and graphical output you want to include in the report.

7. Shut down R/RStudio: this requires a decision whether to save the R objects generated during the workflow.

## Finding & loading data

As demonstrated above, you can specify the full path to any file on the harddisk for reading it in via `read.table`. However, I recommend setting R's default directory, the _working directory_, right at the start of the analysis. This makes it easier to keep track of files that you generate while working on this specific data.

The working directory can be set at the command prompt:
```{r, eval = c(1,3)}
setwd("Z:/OmicsDataAnalysis/")
#setwd("~/@ownCloudKI/OmicsDataAnalysis/")
dir()
```
Note that my working directory has a number of sub-folders, which is generally a good idea if your project involves more than a handful of files.

After setting the working directory, all further file operations that do not explicity start at the root of the file system will be _relative_ to the working directory. So in order to read the file `qPCR.txt` in sub-folder `Data`, it is sufficient to run^[Another round of tab-expansions: once you have placed the cursor between the quotation marks, you can start to type the file name, and hit tab to show a list of available files in the working directory.]
```{r}
ex1 <- read.table("Data/qPCR.txt", header=TRUE)
str(ex1)
```
Alternatively, you can use the GUI to set the working directory: both R and RStudio have menu items for that (`File/Change dir` and `Session/Set working dir`, respectively). RStudio also offers the Files pane, where you can explore the directory tree interactively to set a working directory.

\begin{marginfigure}
\centering 
\includegraphics[width=\textwidth]{figures/RStudio_1_2_5001_Windows10_FileTab.png}\caption{RStudio Files pane}
\end{marginfigure}


## Descriptive statistics

A useful function for generic descriptives is `summary`: if the argument is a numerical vector, it will display a number of location measures (minimum, maximum, mean, median and the first and third quartile); if the argument is either a factor vector, the function will return a frequency table. Coveniently, when the argument is a data frame, it will return a summary for each variable, depending on type: 
```{r, R.options = list(width = 75)}
summary(ex1)
```
This can be combined with other summary statistics of interest, like `sd` for standard deviations and `IQR` for the interquartile range. 
 
## Plots

R has a very rich set of graphical functions, including three independent systems for generating high-level plots. The examples shown here are from the oldest system, the _base graphics_, which is directly available in R.^[The other two systems are ggplot2 and lattice, respectively. Both require that an add-on package of the same name is installed and loaded.]

The function `hist` takes a numerical vector as argument and draws a histogram in the current plotting window:
```{r, fig.margin = TRUE, fig.cap = 'Histogram of DeltaCt', fig.width=3.5, fig.height=3.5}
hist(ex1$DeltaCt)
```
The function `boxplot` can draw boxplots of values of a given variable for separate groups of subjects, given by another variable. This draws separate boxplots for the relative strength of gene expression `DeltaCt` for the two groups of measurements as seen in grouping variable `Sample`:
```{r, fig.margin = TRUE, fig.cap = 'Boxplot of DeltaCt by group', fig.width=3.5, fig.height=3.5}
boxplot(DeltaCt ~ Sample, ex1)
```
The first argument in this function call is a _formula_, an R construction that is widely used for specifying e.g. plots and regression models; the tilde character `~` is best read "as a function of", so here "plot `DeltaCt` as a function of `Sample`" (where both variables are taken from the data frame `ex1`, as specified by the second argument).

With regard to the plot itself, we see that the expression levels are clearly higher among controls than among cases, and that there is a suspiciously large value among the controls - interesting for the report?

Base graphics look a rather old-fashioned, but are straightforward to create, and can be prettified in many ways, using titles, labels, colors, fonts etc., all of which goes beyond the range of this document.^[See however ????] 

## Statistical tests

For the current example, a simple t-test for the null hypothesis that the mean gene expression level (averaged across all concentrations) is the same for both treated plants and untreated controls seems a reasonable sort of inference. This can be done via the function `t.test`: 
```{r}
t.test(DeltaCt ~ Sample, data = ex1)
```               
The function call and the result for this test are very similar to most other basic tests, so let's have a look:

* The outcome and grouping variable as well as the data frame where they live are specified as before via a formula.
* The first row of the output states the test used: here, the Walch t-test, which does not assume equal variances between groups (which the Student t-test does).
* This is followed by information on the data used, the test statistic, and the p-value for the null hypothesis; here, a p-value of less than 3.5E-5 indicates that the difference is statistically significant at most conventional significance levels. 
* The test does not state the null hypothesis, but the alternative hypothesis: here, a simple two-sided alternative, i.e. we reject the null hypothesis of equal means for both large negative and large postive mean differences.
* This is followed by a number of descriptive statistics, here: a 95% confidence interval for the mean difference between groups, and the respective group means. 

The results here are very similar to the results in Table 3 of the original publication (and would be identical if we had chosen the Student t-test instead of Walch.)


## Export results

Results to be included in a report can be exported manually: text output can be selected in the console, copied to the clipboard, and pasted into the target document. Graphs can be extracted via the `Export`-menu in the plot tab, and either be saved to an image file, or again copied to the clipboard.^[In base R, the same functionality is available via right-clicking the plot window] 

Manual export / copying and pasting is reasonably fast and convenient for a few numbers and plots, but generally not recommended, because it breaks the connection between the R code use to generate the results and the results themselves: this is a common source of errors that hard to track. It also has to be repeated whenever the data or the analysis changes, and formatting even moderately large result tables becomes very time consuming.

Therefore, results should generally be exported as part of an analysis script that automates both analysis and extraction of the desired results, see ???.

## Shut down R

Terminating an R session is easy: select the `Quit`-entry in the `File`-menu, or kill the program window, or use the command `q()` in the console. 
However, by default, all data, results, and plots generated during an R/RStudio session will be lost when quitting R, unless you take steps to save them for later. Therefore, by default, R will always offer to save the _workspace image_ when you quit a session: this means that all currently defined objects will be saved to a file called `.RData` in the current working directory. This file can later be loaded via the `Load workspace`-entry in the `Session`-menu.^[In base R, in the File-menu], or via the `load()` command in the console.^[If the current working directory is also the start-up directory for R/RStudio, this .RData file will be loaded automatically at the start of the next session, with a message in the console.]

Note that you can save the current workspace image at any time via the `Environment`-tab or the `save.image()`-command.^[Image: Environment pane]

In addition, RStudio will also save all the R commands used in the current R session (as seen in the `History`-pane) to a file `.Rhistory` in the current working directory.^[By default, RStudio will always save the history, but base R only when also saving the workspace image.] This is a simple text file that can be opened in any text editor, or re-loaded into R via `History`-pane or the `loadhistory()`-command. 

\newpage

# Bulding a simple script

A simple scripted analysis flow

## Building a script

Easiest: interactive analysis $\Rightarrow$ script

Re-use commands via **History** tab: select commands and

* `To Console`: copy to prompt 
* `To Console`: copy to text file

\ldots for editing & execution.

**Editor** pane: multi-tabbed text editor

* syntax coloring
* command completion via tab
* direct execution of code at console via `Ctrl-Return`

## Why scripts?

**Replicability**:

* data + code can replicate analysis
* data + results generally canNOT

Modifiability, documentation, nice output\ldots: yes, that too

Make life easy for yourself & others:

* Use comments (everything after `#` until end of line)
* Add header (aka meta-data, aka what, who, when)


## From script to (draft) report

"Compile report" -- stupid name

1. Write script in editor pane
2. Click on the _Compile report_ icon \raisebox{-.5\height}{\includegraphics[width=0.1\textwidth]{figures/CompileReport.png}}
3. Choose desired output format (HTML, PDF, Word)
4. R will 
 
    * Run script
    * Combine code and output
    * Convert to desired format

Draft output can be edited for full report

`r tufte::margin_note("see literate programming, R markdown, knitr for more!")`


\newpage

# Going forward

## Finding useful packages

1. Generic: CRAN \url{https://cran.r-project.org/}

    * Comprehensive R Archive Network
    * 10,000+ packages
    * Installation via **Packages** tab, `install.packages`
    * Curated collections: Task views

2. Bioconductor: \url{https://www.bioconductor.org/}

    * Collection of R packages for bioinf / omics
    * 1,500+ packages
    * Installation via 	`BiocManager::install`
    * Collections: BiocViews 

\begin{frame}{How to find BioC packages}

Example: bacterial microbiome, 16S sequencing

* output from pre-processing pipeline
* OTU table, inferred taxonomy and phylogeny, subject phenotypes

Explore BioCViews: \url{https://www.bioconductor.org/packages/release/BiocViews.html}

Candidate packages: 

* \url{https://www.bioconductor.org/packages/release/bioc/html/microbiome.html}
* \url{https://www.bioconductor.org/packages/release/bioc/html/phyloseq.html}


## How to use a BioC package

Example: annotate the protein data 

See script `omicsExample2b.R`

## There is more!

Alternative packages

* `ggplot2`: complete modern plotting system
* `dplyr`: powerful data manipulation 
* `data.table`: alternative to data frame for large data sets
* `rmarkdown`: advanced mixing of code / results
* `limma`: linear models for many features
* `biomaRt`: interfaces to online repositories
* \ldots

\appendix

# Resources

* CRAN contributed documentation \\
\url{https://cran.r-project.org/other-docs.html}
* BioC common workflows \\ \url{http://bioconductor.org/packages/release/workflows/} 
* BioC contributed documentation \\ \url{http://bioconductor.org/help/community/}
* BioC course material \\ \url{http://bioconductor.org/help/course-materials/}
* BioC featured publications \\ \url{http://bioconductor.org/help/publications/index.html}

